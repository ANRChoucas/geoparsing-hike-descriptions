{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrOKr9pwkxJw"
   },
   "source": [
    "# GEOPARSING FOR HIKE DESCRIPTIONS\n",
    "\n",
    "This notebook is proposed by [L. Moncla](https://ludovicmoncla.github.io/) as part of the [CHOUCAS](http://choucas.ign.fr/) (2017-2021) project.\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we'll learn about a few different things.\n",
    "\n",
    "- How to use the [PERDIDO API](http://erig.univ-pau.fr/PERDIDO/api.jsp) for geoparsing (geotagging + geocoding) French hike descriptions\n",
    "- Display custom geotagging results (PERDIDO TEI-XML) with the [displaCy Named Entity Visualizer](https://spacy.io/usage/visualizers)\n",
    "- Display geocoding results on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gi1PFqtkxJy"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Geoparsing (also known as toponym resolution) refers to the process of extracting place names from text and assigning geographic coordinates to them.\n",
    "This involves two main tasks: geotagging and geocoding.\n",
    "Geotagging consists to identify spans of text referring to place names while geocoding consists to find unambiguous geographic coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The geotagging service of the PERDIDO API uses a cascade of finite-state transducers defining specific patterns for NER and identification of geographic information (spatial relations, etc.). \n",
    "> Gaio, M. and Moncla, L. (2019). \"Geoparsing and geocoding places in a dynamic space context.\" In The Semantics of Dynamic Space in French: Descriptive, experimental and formal studies on motion expression, 66, 353.\n",
    "\n",
    "The geocoding task uses a simple gazetteer lookup method. \n",
    "For geocoding French hike description we use the bdnyme database provided by IGN.\n",
    "In this notebook, we'll use the GPS trace associated with each hike description to compute to find the area where entities should be located. This will help to reduce toponym ambiguities during the geocoding step.\n",
    "\n",
    "\n",
    "### PERDIDO Geoparser API\n",
    "\n",
    "\n",
    "The [PERDIDO API](http://erig.univ-pau.fr/PERDIDO/) has been developped for extracting and retrieving displacements from unstructured texts. \n",
    "> Moncla, L., Gaio, M., Nogueras-Iso, J., & Mustière, S. (2016). \"Reconstruction of itineraries from annotated text with an informed spanning tree algorithm.\" International Journal of Geographical Information Science, 30, 1137–1160.\n",
    "\n",
    "In this tutorial we'll see how to use the PERDIDO API for geoparsing French hike descriptions. \n",
    "We will apply geoparsing on some hike descriptions downloaded from the [visorando](https://www.visorando.com/) web sharing platform.\n",
    "\n",
    "The PERDIDO Geoparsing and Geocoding services (`http://erig.univ-pau.fr/PERDIDO/api/geoparsing/`) take 4 parameters:\n",
    "1. api_key: API key of the user\n",
    "2. lang: language of the document (currently only available for French)\n",
    "3. content: textual content to parse\n",
    "4. bbox: allows to filter entities locations using a bounding box. \n",
    "\n",
    "The PERDIDO Geoparser returns XML-TEI. The `<name>` element refers to named entities (proper nouns) and the type attribute indicates its class (place, person, etc.). The `<rs>` element refers to extended named entities (e.g. refuge du Bois). The `<location>` element indicates that geographic coordinates were found during geocoding.  \n",
    "\n",
    "\n",
    "```xml\n",
    "<rs type=\"place\" subtype=\"ene\" start=\"13\" end=\"27\" startT=\"3\" endT=\"6\" id=\"en.13\">\n",
    "   <term type=\"place\" start=\"13\" end=\"19\" startT=\"3\" endT=\"4\">\n",
    "      <w lemma=\"refuge\" type=\"N\" xml:id=\"w4\">Refuge</w>\n",
    "   </term>\n",
    "   <w lemma=\"du\" type=\"PREPDET\" xml:id=\"w5\">du</w>\n",
    "   <rs type=\"unknown\" subtype=\"no\" start=\"23\" end=\"27\" startT=\"5\" endT=\"6\" id=\"en.14\">\n",
    "      <name type=\"unknown\" id=\"en.1\">\n",
    "         <w lemma=\"null\" type=\"NPr\" xml:id=\"w6\">Bois</w>\n",
    "      </name>\n",
    "   </rs>\n",
    "   <location>\n",
    "       <geo source=\"bdnyme\">6.744359 45.459557</geo>\n",
    "   </location>\n",
    "</rs>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "\n",
    "First, you need to register on the PERDIDO website to get your API key: http://erig.univ-pau.fr/PERDIDO/api.jsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if some libraries are not installed on your environment (this is the case with binder)\n",
    "!pip3 install spacy\n",
    "!pip3 install lxml\n",
    "!pip3 install gpxpy\n",
    "!pip3 install geojson\n",
    "!pip3 install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import glob\n",
    "\n",
    "from spacy.tokens import Span\n",
    "from spacy.tokens import Doc\n",
    "from spacy.vocab import Vocab\n",
    "from spacy import displacy\n",
    "\n",
    "import lxml.etree as etree\n",
    "\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "\n",
    "import geojson\n",
    "import folium\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function Perdido2displaCy()\n",
    "    transforms the PERDIDO-NER XML output into spaCy format (for display purpose) '''\n",
    "def Perdido2displaCy(contentXML):\n",
    "    vocab = Vocab()\n",
    "    words = []\n",
    "    spaces = []\n",
    "    root = etree.fromstring(bytes(contentXML, 'utf-8'))\n",
    "    contentTXT = \"\"\n",
    "    for w in root.findall('.//w'):\n",
    "        contentTXT += w.text + ' '\n",
    "        words.append(w.text)\n",
    "        spaces.append(True)\n",
    "    doc = Doc(vocab, words=words, spaces=spaces)\n",
    "    ents = [] \n",
    "    for child in root.findall('.//location'):\n",
    "        rs = get_parent(child, 'rs')\n",
    "        if rs is not None:\n",
    "            if not loc_in_parent(rs):\n",
    "                if 'startT' in rs.attrib:\n",
    "                    start = rs.get('startT')\n",
    "                    if 'endT' in rs.attrib:\n",
    "                        stop = rs.get('endT')\n",
    "                        type = 'LOC'\n",
    "                        ents.append(Span(doc, int(start), int(stop), label=type))          \n",
    "    for child in root.findall('.//rs[@type=\"place\"]'):\n",
    "        if not parent_exists(child, 'rs', 'place'):\n",
    "            if not loc_in_child(child):\n",
    "                if 'startT' in child.attrib:\n",
    "                    start = child.get('startT')\n",
    "                    if 'endT' in child.attrib:\n",
    "                        stop = child.get('endT')\n",
    "                        type = 'MISC'\n",
    "                        ents.append(Span(doc, int(start), int(stop), label=type))       \n",
    "    doc.ents = ents\n",
    "    return doc \n",
    "\n",
    "\n",
    "''' function parent_exists() \n",
    "    returns True if one of the ancestor of the element child_node have the name name_node''' \n",
    "def parent_exists(child_node, name_node):\n",
    "    try:\n",
    "        parent_node = next(child_node.iterancestors())\n",
    "        if parent_node.tag == name_node:\n",
    "            if 'startT' in parent_node.attrib:\n",
    "                return True\n",
    "        return parent_exists(parent_node, name_node)\n",
    "    except StopIteration:\n",
    "        return False\n",
    "\n",
    "    \n",
    "''' function parent_exists() \n",
    "    returns True if one of the ancestor of the element child_node have the name name_node''' \n",
    "def parent_exists(child_node, name_node, type_val):\n",
    "    try:\n",
    "        parent_node = next(child_node.iterancestors())\n",
    "        if parent_node.tag == name_node:\n",
    "            if 'type' in parent_node.attrib:\n",
    "                if parent_node.get('type') == type_val:\n",
    "                    if 'startT' in parent_node.attrib:\n",
    "                        return True\n",
    "        return parent_exists(parent_node, name_node, type_val)\n",
    "    except StopIteration:\n",
    "        return False\n",
    "\n",
    "''' function loc_in_parent() \n",
    "    returns a boolean, true if the element location is found in the <rs> ancestor or false ''' \n",
    "def loc_in_parent(node):\n",
    "    try:\n",
    "        parent_node = next(node.iterancestors())\n",
    "        if parent_node.tag == \"rs\":\n",
    "            if parent_node.find('location') is not None:\n",
    "                return True\n",
    "            else:\n",
    "                return loc_in_parent(parent_node)\n",
    "        else:\n",
    "            return False\n",
    "    except StopIteration:\n",
    "        return False\n",
    "\n",
    "    \n",
    "''' function loc_in_child() \n",
    "    returns a boolean, true if the element location is found in a child element or false ''' \n",
    "def loc_in_child(node):\n",
    "    #root.find('./text/body/div1/index[@type=\"head\"]').get('value')\n",
    "    child_node = node.find('.//location')\n",
    "    if child_node is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "''' function get_parent() \n",
    "    returns the first ancestor of the element child_node that have the name name_node ''' \n",
    "def get_parent(child_node, name_node):\n",
    "    try:\n",
    "        parent_node = next(child_node.iterancestors())\n",
    "        if parent_node.tag == name_node:\n",
    "            if 'startT' in parent_node.attrib:\n",
    "                return parent_node\n",
    "        return get_parent(parent_node, name_node)\n",
    "    except StopIteration:\n",
    "        return None\n",
    "    \n",
    "\n",
    "''' function display_map() display the map using the folium library '''\n",
    "def display_map(json_data):\n",
    "    coords = list(geojson.utils.coords(json_data))\n",
    "    \n",
    "    ave_lat = sum(p[0] for p in coords)/len(coords)\n",
    "    ave_lon = sum(p[1] for p in coords)/len(coords)\n",
    "    \n",
    "    if len(coords) > 0:\n",
    "        print(str(len(coords))+\" records found in gazetteer:\")\n",
    "\n",
    "        m = folium.Map(location=[ave_lat, ave_lon], zoom_start=12)\n",
    "        folium.GeoJson(data, name='Toponyms', tooltip=folium.features.GeoJsonTooltip(fields=['id', 'name', 'source'], localize=True)).add_to(m)\n",
    "\n",
    "        display(m)\n",
    "    else:\n",
    "        print(\"Sorry, no records found in gazetteer for geocoding!\")\n",
    "        \n",
    "        \n",
    "''' function display_map_gpx() display the map using the folium library '''\n",
    "def display_map_gpx(json_data, gpx_filename):\n",
    "    \n",
    "    gpx = gpxpy.parse(open(gpx_filename, 'r'))\n",
    "    \n",
    "    points = []\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:        \n",
    "            for point in segment.points:\n",
    "                points.append(tuple([point.latitude, point.longitude]))\n",
    "    #print(points)\n",
    "    ave_lat = sum(p[0] for p in points)/len(points)\n",
    "    ave_lon = sum(p[1] for p in points)/len(points)\n",
    "    \n",
    "    m = folium.Map(location=[ave_lat, ave_lon], zoom_start=12)\n",
    "    \n",
    "    folium.PolyLine(points, color=\"red\", weight=2.5, opacity=1).add_to(m)\n",
    "    \n",
    "    coords = list(geojson.utils.coords(json_data))\n",
    "    \n",
    "    if len(coords) > 0:\n",
    "        print(str(len(coords))+\" records found in gazetteer:\")\n",
    "        folium.GeoJson(json_data, name='Toponyms', tooltip=folium.features.GeoJsonTooltip(fields=['id', 'name', 'source'], localize=True)).add_to(m)       \n",
    "    else:\n",
    "        print(\"Sorry, no records found in gazetteer for geocoding!\")\n",
    "        \n",
    "    display(m)\n",
    "    \n",
    "            \n",
    "''' function get_bbox() returns the bounding box of a given GPS trace '''\n",
    "def get_bbox(gpx_filename):\n",
    "    \n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    elevations = []\n",
    "   \n",
    "    gpx = gpxpy.parse(open(gpx_filename, 'r'))\n",
    "    \n",
    "    points = []\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                latitudes.append(point.latitude)\n",
    "                longitudes.append(point.longitude)\n",
    "                elevations.append(point.elevation)\n",
    "\n",
    "    return str(min(longitudes))+' '+str(min(latitudes))+' '+str(max(longitudes))+' '+str(max(latitudes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'demo' # !! replace by yours\n",
    "lang = 'French'  # currently only available for French\n",
    "version = 'Standard' # default: Standard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of txt files from the data directory\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"data/*.txt\"):\n",
    "    txtfiles.append(file[:-4])\n",
    "    \n",
    "print(txtfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the textual content from file\n",
    "file = open(txtfiles[0]+\".txt\", \"r\")\n",
    "\n",
    "content = \"\"\n",
    "for paragraph in file:\n",
    "    content += paragraph\n",
    "    \n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bounding box from the gps trace\n",
    "gpx_filename = txtfiles[0]+\".gpx\"\n",
    "bbox = get_bbox(gpx_filename)\n",
    "\n",
    "#print(bbox)\n",
    "\n",
    "# set the parameters for the PERDIDO API\n",
    "parameters = {'api_key': api_key, \n",
    "              'lang': lang, \n",
    "              'content': content, \n",
    "              \"bbox\": bbox}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the geoparsing REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://erig.univ-pau.fr/PERDIDO/api/geoparsing/', params=parameters)\n",
    "print(r.text) # shows the result of the request\n",
    "#you can parse this XML to retrieve the information you are interested in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells, we will use the displacy library from spaCy to display the PERDIDO-NER XML output. For this purpose, we defined the function `Perdido2displaCy()` in order to transform the PERDIDO-NER XML into a [spaCy](https://spacy.io/) compatible format. Geocoded toponyms are marked in orange (with the label: LOC) while toponyms that are not associated with a location are marked in grey (with the label: MISC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Perdido2displaCy(r.text)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the geocoding REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('http://erig.univ-pau.fr/PERDIDO/api/geocoding/', params=parameters)\n",
    "\n",
    "#print(\"geojson : \"+r.text) ## you can save the geojson in a file if needed\n",
    "\n",
    "data = geojson.loads(r.text)\n",
    "\n",
    "display_map_gpx(data, gpx_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(txtfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose the file you want to process among the 30 hike descriptions\n",
    "id_file = 11\n",
    "\n",
    "file = open(txtfiles[id_file]+\".txt\", \"r\")\n",
    "\n",
    "# get the textual content from file\n",
    "content = \"\"\n",
    "for paragraph in file:\n",
    "    content += paragraph\n",
    "    \n",
    "gpx_filename = txtfiles[id_file]+\".gpx\"\n",
    "\n",
    "bbox = get_bbox(gpx_filename)\n",
    "\n",
    "parameters = {'api_key': api_key, \n",
    "              'lang': lang, \n",
    "              'content': content, \n",
    "              \"bbox\": bbox}\n",
    "\n",
    "r = requests.get('http://erig.univ-pau.fr/PERDIDO/api/geoparsing/', params=parameters)\n",
    "displacy.render(Perdido2displaCy(r.text), style=\"ent\", jupyter=True)\n",
    "\n",
    "r = requests.get('http://erig.univ-pau.fr/PERDIDO/api/geocoding/', params=parameters)\n",
    "display_map_gpx(geojson.loads(r.text), gpx_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Geoparsing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
